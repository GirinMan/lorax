llmDeployment:
  name: ""
  namespace: ""
  replicas: 1
  updateStrategy: RollingUpdate

  image:
    repository: "ghcr.io/predibase/lorax"
    tag: "f76119a"
  args:
    modelId: ""
    maxInputLength: 512
    maxTotalTokens: 1024
    maxBatchTotalTokens: 4096
    maxBatchPrefillTokens: 2048
    sharded: true
  env:
    huggingFaceHubToken: ""
    loraxEnabledModelTypes: "llama,mistral"
  nodeSelector: {} 
  resources:
    limits:
      cpu: "8"
      ephemeral-storage: 100Gi
      memory: 27041Mi
      nvidia.com/gpu: "1"
    requests:
      cpu: "8"
      ephemeral-storage: 100Gi
      memory: 27041Mi
      nvidia.com/gpu: "1"

llmService:
  serviceType: LoadBalancer

